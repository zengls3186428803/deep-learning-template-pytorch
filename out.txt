{'model': {'embed_dim': 100, 'n_head': 1, 'dropout': 0.5, 'n_block_gpt': 10, 'batch_first': True, 'batch_size': 8, 'max_gen_len': 128, 'max_pos': 2000}, 'data': {'batch_size': 32, 'test_batch_size': 32}, 'algorithm': {'learning_rate': 0.01, 'optimizer': 'Adam'}, 'train': {'num_epochs': 100, 'save_interval': 20, 'evaluate_interval_steps': 99999, 'evaluate_interval_epochs': 1, 'seed': 415, 'save_strategy': 'step', 'save_steps': 1000, 'save_epochs': 1, 'device': 'cuda', 'save_interval_epochs': 5, 'save_interval_steps': 1000}, 'wandb': {'project': 'gpt2', 'entity': 'superposed-tree', 'mode': 'disabled', 'group': 'gpt2_group'}}
module_list:['fc.0', 'fc.1', 'fc.2', 'fc.3', 'fc.4', 'fc.5', 'fc.6', 'fc.7', 'fc.8', 'fc.9', 'fc.10', 'fc.11', 'fc.12', 'fc.13', 'fc.14', 'fc.15', 'fc.16', 'fc.17', 'fc.18', 'fc.19', 'fc.20', 'fc.21', 'fc.22', 'fc.23', 'fc.24', 'fc.25', 'fc.26', 'fc.27', 'fc.28', 'fc.29', 'fc.30', 'fc.31', 'fc.32', 'fc.33', 'fc.34', 'fc.35', 'fc.36', 'fc.37', 'fc.38', 'fc.39', 'fc.40', 'fc.41', 'fc.42', 'fc.43', 'fc.44', 'fc.45', 'fc.46', 'fc.47', 'fc.48', 'fc.49', 'fc.50', 'fc.51', 'fc.52', 'fc.53', 'fc.54', 'fc.55', 'fc.56', 'fc.57', 'fc.58', 'fc.59', 'fc.60', 'fc.61', 'fc.62', 'fc.63', 'fc.64', 'fc.65', 'fc.66', 'fc.67', 'fc.68', 'fc.69', 'fc.70', 'fc.71', 'fc.72', 'fc.73', 'fc.74', 'fc.75', 'fc.76', 'fc.77', 'fc.78', 'fc.79', 'fc.80', 'fc.81', 'fc.82', 'fc.83', 'fc.84', 'fc.85', 'fc.86', 'fc.87', 'fc.88', 'fc.89', 'fc.90', 'fc.91', 'fc.92', 'fc.93', 'fc.94', 'fc.95', 'fc.96', 'fc.97', 'fc.98', 'fc.99', 'fc.100', 'fc.101', 'fc.102', 'fc.103', 'fc.104', 'fc.105', 'fc.106', 'fc.107', 'fc.108', 'fc.109', 'fc.110', 'fc.111', 'fc.112', 'fc.113', 'fc.114', 'fc.115', 'fc.116', 'fc.117', 'fc.118', 'fc.119', 'fc.120', 'fc.121', 'fc.122', 'fc.123', 'fc.124', 'fc.125', 'fc.126', 'fc.127', 'fc.128', 'fc.129', 'fc.130', 'fc.131', 'fc.132', 'fc.133', 'fc.134', 'fc.135', 'fc.136', 'fc.137', 'fc.138', 'fc.139', 'fc.140', 'fc.141', 'fc.142', 'fc.143', 'fc.144', 'fc.145', 'fc.146', 'fc.147', 'fc.148', 'fc.149', 'fc.150', 'fc.151', 'fc.152', 'fc.153', 'fc.154', 'fc.155', 'fc.156', 'fc.157', 'fc.158', 'fc.159', 'fc.160', 'fc.161', 'fc.162', 'fc.163', 'fc.164', 'fc.165', 'fc.166', 'fc.167', 'fc.168', 'fc.169', 'fc.170', 'fc.171', 'fc.172', 'fc.173', 'fc.174', 'fc.175', 'fc.176', 'fc.177', 'fc.178', 'fc.179', 'fc.180', 'fc.181', 'fc.182', 'fc.183', 'fc.184', 'fc.185', 'fc.186', 'fc.187', 'fc.188', 'fc.189', 'fc.190', 'fc.191', 'fc.192', 'fc.193', 'fc.194', 'fc.195', 'fc.196', 'fc.197', 'fc.198', 'fc.199', 'fc.200', 'fc.201', 'fc.202', 'fc.203', 'fc.204', 'fc.205', 'fc.206', 'fc.207', 'fc.208', 'fc.209', 'fc.210', 'fc.211', 'fc.212', 'fc.213', 'fc.214', 'fc.215', 'fc.216', 'fc.217', 'fc.218', 'fc.219', 'fc.220', 'fc.221', 'fc.222', 'fc.223', 'fc.224', 'fc.225', 'fc.226', 'fc.227', 'fc.228', 'fc.229', 'fc.230', 'fc.231', 'fc.232', 'fc.233', 'fc.234', 'fc.235', 'fc.236', 'fc.237', 'fc.238', 'fc.239', 'fc.240', 'fc.241', 'fc.242', 'fc.243', 'fc.244', 'fc.245', 'fc.246', 'fc.247', 'fc.248', 'fc.249', 'fc.250', 'fc.251', 'fc.252', 'fc.253', 'fc.254', 'fc.255', 'fc.256', 'fc.257', 'fc.258', 'fc.259', 'fc.260', 'fc.261', 'fc.262', 'fc.263', 'fc.264', 'fc.265', 'fc.266', 'fc.267', 'fc.268', 'fc.269', 'fc.270', 'fc.271', 'fc.272', 'fc.273', 'fc.274', 'fc.275', 'fc.276', 'fc.277', 'fc.278', 'fc.279', 'fc.280', 'fc.281', 'fc.282', 'fc.283', 'fc.284', 'fc.285', 'fc.286', 'fc.287', 'fc.288', 'fc.289', 'fc.290', 'fc.291', 'fc.292', 'fc.293', 'fc.294', 'fc.295', 'fc.296', 'fc.297', 'fc.298', 'fc.299', 'fc.300', 'fc.301', 'fc.302', 'fc.303', 'fc.304', 'fc.305', 'fc.306', 'fc.307', 'fc.308', 'fc.309', 'fc.310', 'fc.311', 'fc.312', 'fc.313', 'fc.314', 'fc.315', 'fc.316', 'fc.317', 'fc.318', 'fc.319', 'fc.320', 'fc.321', 'fc.322', 'fc.323', 'fc.324', 'fc.325', 'fc.326', 'fc.327', 'fc.328', 'fc.329', 'fc.330', 'fc.331', 'fc.332', 'fc.333', 'fc.334', 'fc.335', 'fc.336', 'fc.337', 'fc.338', 'fc.339', 'fc.340', 'fc.341', 'fc.342', 'fc.343', 'fc.344', 'fc.345', 'fc.346', 'fc.347', 'fc.348', 'fc.349', 'fc.350', 'fc.351', 'fc.352', 'fc.353', 'fc.354', 'fc.355', 'fc.356', 'fc.357', 'fc.358', 'fc.359', 'fc.360', 'fc.361', 'fc.362', 'fc.363', 'fc.364', 'fc.365', 'fc.366', 'fc.367', 'fc.368', 'fc.369', 'fc.370', 'fc.371', 'fc.372', 'fc.373', 'fc.374', 'fc.375', 'fc.376', 'fc.377', 'fc.378', 'fc.379', 'fc.380', 'fc.381', 'fc.382', 'fc.383', 'fc.384', 'fc.385', 'fc.386', 'fc.387', 'fc.388', 'fc.389', 'fc.390', 'fc.391', 'fc.392', 'fc.393', 'fc.394', 'fc.395', 'fc.396', 'fc.397', 'fc.398', 'fc.399']
{'fc.0': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': True, 'last_module_flag': False}, 'fc.1': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.2': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.3': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.4': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.5': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.6': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.7': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.8': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.9': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.10': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.11': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.12': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.13': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.14': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.15': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.16': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.17': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.18': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.19': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.20': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.21': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.22': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.23': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.24': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.25': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.26': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.27': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.28': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.29': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.30': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.31': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.32': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.33': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.34': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.35': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.36': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.37': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.38': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.39': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.40': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.41': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.42': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.43': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.44': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.45': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.46': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.47': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.48': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.49': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.50': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.51': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.52': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.53': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.54': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.55': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.56': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.57': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.58': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.59': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.60': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.61': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.62': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.63': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.64': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.65': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.66': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.67': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.68': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.69': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.70': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.71': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.72': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.73': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.74': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.75': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.76': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.77': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.78': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.79': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.80': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.81': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.82': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.83': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.84': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.85': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.86': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.87': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.88': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.89': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.90': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.91': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.92': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.93': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.94': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.95': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.96': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.97': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.98': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.99': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.100': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.101': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.102': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.103': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.104': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.105': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.106': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.107': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.108': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.109': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.110': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.111': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.112': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.113': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.114': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.115': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.116': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.117': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.118': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.119': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.120': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.121': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.122': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.123': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.124': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.125': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.126': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.127': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.128': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.129': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.130': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.131': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.132': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.133': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.134': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.135': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.136': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.137': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.138': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.139': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.140': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.141': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.142': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.143': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.144': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.145': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.146': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.147': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.148': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.149': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.150': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.151': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.152': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.153': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.154': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.155': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.156': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.157': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.158': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.159': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.160': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.161': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.162': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.163': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.164': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.165': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.166': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.167': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.168': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.169': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.170': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.171': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.172': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.173': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.174': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.175': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.176': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.177': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.178': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.179': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.180': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.181': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.182': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.183': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.184': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.185': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.186': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.187': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.188': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.189': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.190': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.191': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.192': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.193': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.194': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.195': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.196': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.197': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.198': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': False}, 'fc.199': {'first_block_flag': True, 'last_block_flag': False, 'first_module_flag': False, 'last_module_flag': True}, 'fc.200': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': True, 'last_module_flag': False}, 'fc.201': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.202': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.203': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.204': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.205': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.206': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.207': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.208': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.209': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.210': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.211': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.212': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.213': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.214': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.215': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.216': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.217': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.218': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.219': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.220': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.221': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.222': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.223': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.224': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.225': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.226': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.227': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.228': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.229': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.230': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.231': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.232': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.233': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.234': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.235': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.236': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.237': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.238': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.239': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.240': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.241': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.242': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.243': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.244': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.245': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.246': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.247': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.248': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.249': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.250': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.251': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.252': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.253': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.254': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.255': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.256': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.257': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.258': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.259': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.260': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.261': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.262': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.263': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.264': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.265': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.266': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.267': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.268': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.269': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.270': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.271': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.272': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.273': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.274': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.275': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.276': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.277': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.278': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.279': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.280': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.281': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.282': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.283': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.284': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.285': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.286': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.287': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.288': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.289': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.290': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.291': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.292': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.293': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.294': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.295': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.296': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.297': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.298': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.299': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.300': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.301': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.302': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.303': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.304': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.305': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.306': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.307': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.308': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.309': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.310': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.311': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.312': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.313': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.314': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.315': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.316': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.317': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.318': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.319': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.320': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.321': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.322': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.323': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.324': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.325': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.326': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.327': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.328': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.329': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.330': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.331': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.332': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.333': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.334': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.335': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.336': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.337': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.338': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.339': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.340': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.341': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.342': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.343': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.344': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.345': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.346': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.347': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.348': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.349': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.350': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.351': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.352': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.353': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.354': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.355': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.356': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.357': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.358': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.359': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.360': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.361': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.362': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.363': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.364': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.365': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.366': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.367': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.368': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.369': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.370': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.371': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.372': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.373': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.374': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.375': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.376': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.377': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.378': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.379': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.380': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.381': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.382': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.383': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.384': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.385': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.386': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.387': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.388': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.389': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.390': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.391': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.392': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.393': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.394': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.395': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.396': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.397': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.398': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': False}, 'fc.399': {'first_block_flag': False, 'last_block_flag': True, 'first_module_flag': False, 'last_module_flag': True}}
__enter__(self):
register_hook_by_block(self, module, parent_name=fc.0
register_hook_by_block(self, module, parent_name=fc.1
register_hook_by_block(self, module, parent_name=fc.2
register_hook_by_block(self, module, parent_name=fc.3
register_hook_by_block(self, module, parent_name=fc.4
register_hook_by_block(self, module, parent_name=fc.5
register_hook_by_block(self, module, parent_name=fc.6
register_hook_by_block(self, module, parent_name=fc.7
register_hook_by_block(self, module, parent_name=fc.8
register_hook_by_block(self, module, parent_name=fc.9
register_hook_by_block(self, module, parent_name=fc.10
register_hook_by_block(self, module, parent_name=fc.11
register_hook_by_block(self, module, parent_name=fc.12
register_hook_by_block(self, module, parent_name=fc.13
register_hook_by_block(self, module, parent_name=fc.14
register_hook_by_block(self, module, parent_name=fc.15
register_hook_by_block(self, module, parent_name=fc.16
register_hook_by_block(self, module, parent_name=fc.17
register_hook_by_block(self, module, parent_name=fc.18
register_hook_by_block(self, module, parent_name=fc.19
register_hook_by_block(self, module, parent_name=fc.20
register_hook_by_block(self, module, parent_name=fc.21
register_hook_by_block(self, module, parent_name=fc.22
register_hook_by_block(self, module, parent_name=fc.23
register_hook_by_block(self, module, parent_name=fc.24
register_hook_by_block(self, module, parent_name=fc.25
register_hook_by_block(self, module, parent_name=fc.26
register_hook_by_block(self, module, parent_name=fc.27
register_hook_by_block(self, module, parent_name=fc.28
register_hook_by_block(self, module, parent_name=fc.29
register_hook_by_block(self, module, parent_name=fc.30
register_hook_by_block(self, module, parent_name=fc.31
register_hook_by_block(self, module, parent_name=fc.32
register_hook_by_block(self, module, parent_name=fc.33
register_hook_by_block(self, module, parent_name=fc.34
register_hook_by_block(self, module, parent_name=fc.35
register_hook_by_block(self, module, parent_name=fc.36
register_hook_by_block(self, module, parent_name=fc.37
register_hook_by_block(self, module, parent_name=fc.38
register_hook_by_block(self, module, parent_name=fc.39
register_hook_by_block(self, module, parent_name=fc.40
register_hook_by_block(self, module, parent_name=fc.41
register_hook_by_block(self, module, parent_name=fc.42
register_hook_by_block(self, module, parent_name=fc.43
register_hook_by_block(self, module, parent_name=fc.44
register_hook_by_block(self, module, parent_name=fc.45
register_hook_by_block(self, module, parent_name=fc.46
register_hook_by_block(self, module, parent_name=fc.47
register_hook_by_block(self, module, parent_name=fc.48
register_hook_by_block(self, module, parent_name=fc.49
register_hook_by_block(self, module, parent_name=fc.50
register_hook_by_block(self, module, parent_name=fc.51
register_hook_by_block(self, module, parent_name=fc.52
register_hook_by_block(self, module, parent_name=fc.53
register_hook_by_block(self, module, parent_name=fc.54
register_hook_by_block(self, module, parent_name=fc.55
register_hook_by_block(self, module, parent_name=fc.56
register_hook_by_block(self, module, parent_name=fc.57
register_hook_by_block(self, module, parent_name=fc.58
register_hook_by_block(self, module, parent_name=fc.59
register_hook_by_block(self, module, parent_name=fc.60
register_hook_by_block(self, module, parent_name=fc.61
register_hook_by_block(self, module, parent_name=fc.62
register_hook_by_block(self, module, parent_name=fc.63
register_hook_by_block(self, module, parent_name=fc.64
register_hook_by_block(self, module, parent_name=fc.65
register_hook_by_block(self, module, parent_name=fc.66
register_hook_by_block(self, module, parent_name=fc.67
register_hook_by_block(self, module, parent_name=fc.68
register_hook_by_block(self, module, parent_name=fc.69
register_hook_by_block(self, module, parent_name=fc.70
register_hook_by_block(self, module, parent_name=fc.71
register_hook_by_block(self, module, parent_name=fc.72
register_hook_by_block(self, module, parent_name=fc.73
register_hook_by_block(self, module, parent_name=fc.74
register_hook_by_block(self, module, parent_name=fc.75
register_hook_by_block(self, module, parent_name=fc.76
register_hook_by_block(self, module, parent_name=fc.77
register_hook_by_block(self, module, parent_name=fc.78
register_hook_by_block(self, module, parent_name=fc.79
register_hook_by_block(self, module, parent_name=fc.80
register_hook_by_block(self, module, parent_name=fc.81
register_hook_by_block(self, module, parent_name=fc.82
register_hook_by_block(self, module, parent_name=fc.83
register_hook_by_block(self, module, parent_name=fc.84
register_hook_by_block(self, module, parent_name=fc.85
register_hook_by_block(self, module, parent_name=fc.86
register_hook_by_block(self, module, parent_name=fc.87
register_hook_by_block(self, module, parent_name=fc.88
register_hook_by_block(self, module, parent_name=fc.89
register_hook_by_block(self, module, parent_name=fc.90
register_hook_by_block(self, module, parent_name=fc.91
register_hook_by_block(self, module, parent_name=fc.92
register_hook_by_block(self, module, parent_name=fc.93
register_hook_by_block(self, module, parent_name=fc.94
register_hook_by_block(self, module, parent_name=fc.95
register_hook_by_block(self, module, parent_name=fc.96
register_hook_by_block(self, module, parent_name=fc.97
register_hook_by_block(self, module, parent_name=fc.98
register_hook_by_block(self, module, parent_name=fc.99
register_hook_by_block(self, module, parent_name=fc.100
register_hook_by_block(self, module, parent_name=fc.101
register_hook_by_block(self, module, parent_name=fc.102
register_hook_by_block(self, module, parent_name=fc.103
register_hook_by_block(self, module, parent_name=fc.104
register_hook_by_block(self, module, parent_name=fc.105
register_hook_by_block(self, module, parent_name=fc.106
register_hook_by_block(self, module, parent_name=fc.107
register_hook_by_block(self, module, parent_name=fc.108
register_hook_by_block(self, module, parent_name=fc.109
register_hook_by_block(self, module, parent_name=fc.110
register_hook_by_block(self, module, parent_name=fc.111
register_hook_by_block(self, module, parent_name=fc.112
register_hook_by_block(self, module, parent_name=fc.113
register_hook_by_block(self, module, parent_name=fc.114
register_hook_by_block(self, module, parent_name=fc.115
register_hook_by_block(self, module, parent_name=fc.116
register_hook_by_block(self, module, parent_name=fc.117
register_hook_by_block(self, module, parent_name=fc.118
register_hook_by_block(self, module, parent_name=fc.119
register_hook_by_block(self, module, parent_name=fc.120
register_hook_by_block(self, module, parent_name=fc.121
register_hook_by_block(self, module, parent_name=fc.122
register_hook_by_block(self, module, parent_name=fc.123
register_hook_by_block(self, module, parent_name=fc.124
register_hook_by_block(self, module, parent_name=fc.125
register_hook_by_block(self, module, parent_name=fc.126
register_hook_by_block(self, module, parent_name=fc.127
register_hook_by_block(self, module, parent_name=fc.128
register_hook_by_block(self, module, parent_name=fc.129
register_hook_by_block(self, module, parent_name=fc.130
register_hook_by_block(self, module, parent_name=fc.131
register_hook_by_block(self, module, parent_name=fc.132
register_hook_by_block(self, module, parent_name=fc.133
register_hook_by_block(self, module, parent_name=fc.134
register_hook_by_block(self, module, parent_name=fc.135
register_hook_by_block(self, module, parent_name=fc.136
register_hook_by_block(self, module, parent_name=fc.137
register_hook_by_block(self, module, parent_name=fc.138
register_hook_by_block(self, module, parent_name=fc.139
register_hook_by_block(self, module, parent_name=fc.140
register_hook_by_block(self, module, parent_name=fc.141
register_hook_by_block(self, module, parent_name=fc.142
register_hook_by_block(self, module, parent_name=fc.143
register_hook_by_block(self, module, parent_name=fc.144
register_hook_by_block(self, module, parent_name=fc.145
register_hook_by_block(self, module, parent_name=fc.146
register_hook_by_block(self, module, parent_name=fc.147
register_hook_by_block(self, module, parent_name=fc.148
register_hook_by_block(self, module, parent_name=fc.149
register_hook_by_block(self, module, parent_name=fc.150
register_hook_by_block(self, module, parent_name=fc.151
register_hook_by_block(self, module, parent_name=fc.152
register_hook_by_block(self, module, parent_name=fc.153
register_hook_by_block(self, module, parent_name=fc.154
register_hook_by_block(self, module, parent_name=fc.155
register_hook_by_block(self, module, parent_name=fc.156
register_hook_by_block(self, module, parent_name=fc.157
register_hook_by_block(self, module, parent_name=fc.158
register_hook_by_block(self, module, parent_name=fc.159
register_hook_by_block(self, module, parent_name=fc.160
register_hook_by_block(self, module, parent_name=fc.161
register_hook_by_block(self, module, parent_name=fc.162
register_hook_by_block(self, module, parent_name=fc.163
register_hook_by_block(self, module, parent_name=fc.164
register_hook_by_block(self, module, parent_name=fc.165
register_hook_by_block(self, module, parent_name=fc.166
register_hook_by_block(self, module, parent_name=fc.167
register_hook_by_block(self, module, parent_name=fc.168
register_hook_by_block(self, module, parent_name=fc.169
register_hook_by_block(self, module, parent_name=fc.170
register_hook_by_block(self, module, parent_name=fc.171
register_hook_by_block(self, module, parent_name=fc.172
register_hook_by_block(self, module, parent_name=fc.173
register_hook_by_block(self, module, parent_name=fc.174
register_hook_by_block(self, module, parent_name=fc.175
register_hook_by_block(self, module, parent_name=fc.176
register_hook_by_block(self, module, parent_name=fc.177
register_hook_by_block(self, module, parent_name=fc.178
register_hook_by_block(self, module, parent_name=fc.179
register_hook_by_block(self, module, parent_name=fc.180
register_hook_by_block(self, module, parent_name=fc.181
register_hook_by_block(self, module, parent_name=fc.182
register_hook_by_block(self, module, parent_name=fc.183
register_hook_by_block(self, module, parent_name=fc.184
register_hook_by_block(self, module, parent_name=fc.185
register_hook_by_block(self, module, parent_name=fc.186
register_hook_by_block(self, module, parent_name=fc.187
register_hook_by_block(self, module, parent_name=fc.188
register_hook_by_block(self, module, parent_name=fc.189
register_hook_by_block(self, module, parent_name=fc.190
register_hook_by_block(self, module, parent_name=fc.191
register_hook_by_block(self, module, parent_name=fc.192
register_hook_by_block(self, module, parent_name=fc.193
register_hook_by_block(self, module, parent_name=fc.194
register_hook_by_block(self, module, parent_name=fc.195
register_hook_by_block(self, module, parent_name=fc.196
register_hook_by_block(self, module, parent_name=fc.197
register_hook_by_block(self, module, parent_name=fc.198
register_hook_by_block(self, module, parent_name=fc.199
register_hook_by_block(self, module, parent_name=fc.200
register_hook_by_block(self, module, parent_name=fc.201
register_hook_by_block(self, module, parent_name=fc.202
register_hook_by_block(self, module, parent_name=fc.203
register_hook_by_block(self, module, parent_name=fc.204
register_hook_by_block(self, module, parent_name=fc.205
register_hook_by_block(self, module, parent_name=fc.206
register_hook_by_block(self, module, parent_name=fc.207
register_hook_by_block(self, module, parent_name=fc.208
register_hook_by_block(self, module, parent_name=fc.209
register_hook_by_block(self, module, parent_name=fc.210
register_hook_by_block(self, module, parent_name=fc.211
register_hook_by_block(self, module, parent_name=fc.212
register_hook_by_block(self, module, parent_name=fc.213
register_hook_by_block(self, module, parent_name=fc.214
register_hook_by_block(self, module, parent_name=fc.215
register_hook_by_block(self, module, parent_name=fc.216
register_hook_by_block(self, module, parent_name=fc.217
register_hook_by_block(self, module, parent_name=fc.218
register_hook_by_block(self, module, parent_name=fc.219
register_hook_by_block(self, module, parent_name=fc.220
register_hook_by_block(self, module, parent_name=fc.221
register_hook_by_block(self, module, parent_name=fc.222
register_hook_by_block(self, module, parent_name=fc.223
register_hook_by_block(self, module, parent_name=fc.224
register_hook_by_block(self, module, parent_name=fc.225
register_hook_by_block(self, module, parent_name=fc.226
register_hook_by_block(self, module, parent_name=fc.227
register_hook_by_block(self, module, parent_name=fc.228
register_hook_by_block(self, module, parent_name=fc.229
register_hook_by_block(self, module, parent_name=fc.230
register_hook_by_block(self, module, parent_name=fc.231
register_hook_by_block(self, module, parent_name=fc.232
register_hook_by_block(self, module, parent_name=fc.233
register_hook_by_block(self, module, parent_name=fc.234
register_hook_by_block(self, module, parent_name=fc.235
register_hook_by_block(self, module, parent_name=fc.236
register_hook_by_block(self, module, parent_name=fc.237
register_hook_by_block(self, module, parent_name=fc.238
register_hook_by_block(self, module, parent_name=fc.239
register_hook_by_block(self, module, parent_name=fc.240
register_hook_by_block(self, module, parent_name=fc.241
register_hook_by_block(self, module, parent_name=fc.242
register_hook_by_block(self, module, parent_name=fc.243
register_hook_by_block(self, module, parent_name=fc.244
register_hook_by_block(self, module, parent_name=fc.245
register_hook_by_block(self, module, parent_name=fc.246
register_hook_by_block(self, module, parent_name=fc.247
register_hook_by_block(self, module, parent_name=fc.248
register_hook_by_block(self, module, parent_name=fc.249
register_hook_by_block(self, module, parent_name=fc.250
register_hook_by_block(self, module, parent_name=fc.251
register_hook_by_block(self, module, parent_name=fc.252
register_hook_by_block(self, module, parent_name=fc.253
register_hook_by_block(self, module, parent_name=fc.254
register_hook_by_block(self, module, parent_name=fc.255
register_hook_by_block(self, module, parent_name=fc.256
register_hook_by_block(self, module, parent_name=fc.257
register_hook_by_block(self, module, parent_name=fc.258
register_hook_by_block(self, module, parent_name=fc.259
register_hook_by_block(self, module, parent_name=fc.260
register_hook_by_block(self, module, parent_name=fc.261
register_hook_by_block(self, module, parent_name=fc.262
register_hook_by_block(self, module, parent_name=fc.263
register_hook_by_block(self, module, parent_name=fc.264
register_hook_by_block(self, module, parent_name=fc.265
register_hook_by_block(self, module, parent_name=fc.266
register_hook_by_block(self, module, parent_name=fc.267
register_hook_by_block(self, module, parent_name=fc.268
register_hook_by_block(self, module, parent_name=fc.269
register_hook_by_block(self, module, parent_name=fc.270
register_hook_by_block(self, module, parent_name=fc.271
register_hook_by_block(self, module, parent_name=fc.272
register_hook_by_block(self, module, parent_name=fc.273
register_hook_by_block(self, module, parent_name=fc.274
register_hook_by_block(self, module, parent_name=fc.275
register_hook_by_block(self, module, parent_name=fc.276
register_hook_by_block(self, module, parent_name=fc.277
register_hook_by_block(self, module, parent_name=fc.278
register_hook_by_block(self, module, parent_name=fc.279
register_hook_by_block(self, module, parent_name=fc.280
register_hook_by_block(self, module, parent_name=fc.281
register_hook_by_block(self, module, parent_name=fc.282
register_hook_by_block(self, module, parent_name=fc.283
register_hook_by_block(self, module, parent_name=fc.284
register_hook_by_block(self, module, parent_name=fc.285
register_hook_by_block(self, module, parent_name=fc.286
register_hook_by_block(self, module, parent_name=fc.287
register_hook_by_block(self, module, parent_name=fc.288
register_hook_by_block(self, module, parent_name=fc.289
register_hook_by_block(self, module, parent_name=fc.290
register_hook_by_block(self, module, parent_name=fc.291
register_hook_by_block(self, module, parent_name=fc.292
register_hook_by_block(self, module, parent_name=fc.293
register_hook_by_block(self, module, parent_name=fc.294
register_hook_by_block(self, module, parent_name=fc.295
register_hook_by_block(self, module, parent_name=fc.296
register_hook_by_block(self, module, parent_name=fc.297
register_hook_by_block(self, module, parent_name=fc.298
register_hook_by_block(self, module, parent_name=fc.299
register_hook_by_block(self, module, parent_name=fc.300
register_hook_by_block(self, module, parent_name=fc.301
register_hook_by_block(self, module, parent_name=fc.302
register_hook_by_block(self, module, parent_name=fc.303
register_hook_by_block(self, module, parent_name=fc.304
register_hook_by_block(self, module, parent_name=fc.305
register_hook_by_block(self, module, parent_name=fc.306
register_hook_by_block(self, module, parent_name=fc.307
register_hook_by_block(self, module, parent_name=fc.308
register_hook_by_block(self, module, parent_name=fc.309
register_hook_by_block(self, module, parent_name=fc.310
register_hook_by_block(self, module, parent_name=fc.311
register_hook_by_block(self, module, parent_name=fc.312
register_hook_by_block(self, module, parent_name=fc.313
register_hook_by_block(self, module, parent_name=fc.314
register_hook_by_block(self, module, parent_name=fc.315
register_hook_by_block(self, module, parent_name=fc.316
register_hook_by_block(self, module, parent_name=fc.317
register_hook_by_block(self, module, parent_name=fc.318
register_hook_by_block(self, module, parent_name=fc.319
register_hook_by_block(self, module, parent_name=fc.320
register_hook_by_block(self, module, parent_name=fc.321
register_hook_by_block(self, module, parent_name=fc.322
register_hook_by_block(self, module, parent_name=fc.323
register_hook_by_block(self, module, parent_name=fc.324
register_hook_by_block(self, module, parent_name=fc.325
register_hook_by_block(self, module, parent_name=fc.326
register_hook_by_block(self, module, parent_name=fc.327
register_hook_by_block(self, module, parent_name=fc.328
register_hook_by_block(self, module, parent_name=fc.329
register_hook_by_block(self, module, parent_name=fc.330
register_hook_by_block(self, module, parent_name=fc.331
register_hook_by_block(self, module, parent_name=fc.332
register_hook_by_block(self, module, parent_name=fc.333
register_hook_by_block(self, module, parent_name=fc.334
register_hook_by_block(self, module, parent_name=fc.335
register_hook_by_block(self, module, parent_name=fc.336
register_hook_by_block(self, module, parent_name=fc.337
register_hook_by_block(self, module, parent_name=fc.338
register_hook_by_block(self, module, parent_name=fc.339
register_hook_by_block(self, module, parent_name=fc.340
register_hook_by_block(self, module, parent_name=fc.341
register_hook_by_block(self, module, parent_name=fc.342
register_hook_by_block(self, module, parent_name=fc.343
register_hook_by_block(self, module, parent_name=fc.344
register_hook_by_block(self, module, parent_name=fc.345
register_hook_by_block(self, module, parent_name=fc.346
register_hook_by_block(self, module, parent_name=fc.347
register_hook_by_block(self, module, parent_name=fc.348
register_hook_by_block(self, module, parent_name=fc.349
register_hook_by_block(self, module, parent_name=fc.350
register_hook_by_block(self, module, parent_name=fc.351
register_hook_by_block(self, module, parent_name=fc.352
register_hook_by_block(self, module, parent_name=fc.353
register_hook_by_block(self, module, parent_name=fc.354
register_hook_by_block(self, module, parent_name=fc.355
register_hook_by_block(self, module, parent_name=fc.356
register_hook_by_block(self, module, parent_name=fc.357
register_hook_by_block(self, module, parent_name=fc.358
register_hook_by_block(self, module, parent_name=fc.359
register_hook_by_block(self, module, parent_name=fc.360
register_hook_by_block(self, module, parent_name=fc.361
register_hook_by_block(self, module, parent_name=fc.362
register_hook_by_block(self, module, parent_name=fc.363
register_hook_by_block(self, module, parent_name=fc.364
register_hook_by_block(self, module, parent_name=fc.365
register_hook_by_block(self, module, parent_name=fc.366
register_hook_by_block(self, module, parent_name=fc.367
register_hook_by_block(self, module, parent_name=fc.368
register_hook_by_block(self, module, parent_name=fc.369
register_hook_by_block(self, module, parent_name=fc.370
register_hook_by_block(self, module, parent_name=fc.371
register_hook_by_block(self, module, parent_name=fc.372
register_hook_by_block(self, module, parent_name=fc.373
register_hook_by_block(self, module, parent_name=fc.374
register_hook_by_block(self, module, parent_name=fc.375
register_hook_by_block(self, module, parent_name=fc.376
register_hook_by_block(self, module, parent_name=fc.377
register_hook_by_block(self, module, parent_name=fc.378
register_hook_by_block(self, module, parent_name=fc.379
register_hook_by_block(self, module, parent_name=fc.380
register_hook_by_block(self, module, parent_name=fc.381
register_hook_by_block(self, module, parent_name=fc.382
register_hook_by_block(self, module, parent_name=fc.383
register_hook_by_block(self, module, parent_name=fc.384
register_hook_by_block(self, module, parent_name=fc.385
register_hook_by_block(self, module, parent_name=fc.386
register_hook_by_block(self, module, parent_name=fc.387
register_hook_by_block(self, module, parent_name=fc.388
register_hook_by_block(self, module, parent_name=fc.389
register_hook_by_block(self, module, parent_name=fc.390
register_hook_by_block(self, module, parent_name=fc.391
register_hook_by_block(self, module, parent_name=fc.392
register_hook_by_block(self, module, parent_name=fc.393
register_hook_by_block(self, module, parent_name=fc.394
register_hook_by_block(self, module, parent_name=fc.395
register_hook_by_block(self, module, parent_name=fc.396
register_hook_by_block(self, module, parent_name=fc.397
register_hook_by_block(self, module, parent_name=fc.398
register_hook_by_block(self, module, parent_name=fc.399
before forward=======================================================
GPU Allocated Memory: 0.78 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:5GB(38%)
CPU memory available :9GB
set OffloadSavedTensorHook.offload_device = offload_device:cpu
set OffloadSavedTensorHook.offload_device = device:cuda
cuda:0
before backward======================================================
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.41 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(43%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(44%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :8GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(45%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(46%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:6GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(47%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(48%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(49%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.41 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(50%)
CPU memory available :7GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[None]
module.device = [device(type='cuda', index=0)]
tensor(0.9888, device='cuda:0', grad_fn=<MseLossBackward0>)
before forward=======================================================
GPU Allocated Memory: 0.41 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:7GB(51%)
CPU memory available :7GB
set OffloadSavedTensorHook.offload_device = offload_device:cpu
set OffloadSavedTensorHook.offload_device = device:cuda
cuda:0
before backward======================================================
GPU Allocated Memory: 0.41 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
GPU Allocated Memory: 0.41 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.41 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(56%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(57%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.02 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.03 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.04 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.05 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.06 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.07 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.08 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.09 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.10 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.11 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.12 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.13 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.14 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.15 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.16 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.17 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.18 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.19 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.20 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.21 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.22 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.23 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.24 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.25 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.26 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.27 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.28 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.29 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.30 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.31 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.32 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.33 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.34 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.35 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.36 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.37 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.38 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.39 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.40 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
after_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)],                 grad_input.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
GPU Allocated Memory: 0.41 GB
GPU max_memory_allocated 1.564453125 GB
CPU memory size of all:15GB
CPU memory used:8GB(58%)
CPU memory available :6GB
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cpu')]
$$$$$
pre_backward_hook: module.name=<class 'torch.nn.modules.linear.Linear'>,                grad_output.device=[device(type='cuda', index=0)]
module.device = [device(type='cuda', index=0)]
